{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af53d12-4507-4051-b2ff-34659114f074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts:\n",
      "buys_computer\n",
      "yes    9\n",
      "no     5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Prior Probabilities:\n",
      "buys_computer\n",
      "yes    0.642857\n",
      "no     0.357143\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#A1\n",
    "import pandas as pd\n",
    "\n",
    "# Replace this with your actual dataset\n",
    "data = {\n",
    "    'age': ['<=30', '<=30', '31...40', '>40', '>40', '>40', '31...40', '<=30', '<=30', '>40', '<=30', '31...40', '31...40', '>40'],\n",
    "    'income': ['high', 'high', 'high', 'medium', 'low', 'low', 'low', 'medium', 'low', 'medium', 'medium', 'medium', 'high', 'medium'],\n",
    "    'student': ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no'],\n",
    "    'credit_rating': ['fair', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'excellent'],\n",
    "    'buys_computer': ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Count the occurrences of each class\n",
    "class_counts = df['buys_computer'].value_counts()\n",
    "\n",
    "# Calculate prior probability for each class\n",
    "prior_probabilities = class_counts / len(df)\n",
    "\n",
    "# Display the results\n",
    "print(\"Class Counts:\")\n",
    "print(class_counts)\n",
    "print(\"\\nPrior Probabilities:\")\n",
    "print(prior_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7172ad5-7a69-4b95-9681-fd2dc1d7ae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: no, Feature: age_numeric\n",
      "Sample Points: [1.         1.02020202 1.04040404 1.06060606 1.08080808 1.1010101\n",
      " 1.12121212 1.14141414 1.16161616 1.18181818 1.2020202  1.22222222\n",
      " 1.24242424 1.26262626 1.28282828 1.3030303  1.32323232 1.34343434\n",
      " 1.36363636 1.38383838 1.4040404  1.42424242 1.44444444 1.46464646\n",
      " 1.48484848 1.50505051 1.52525253 1.54545455 1.56565657 1.58585859\n",
      " 1.60606061 1.62626263 1.64646465 1.66666667 1.68686869 1.70707071\n",
      " 1.72727273 1.74747475 1.76767677 1.78787879 1.80808081 1.82828283\n",
      " 1.84848485 1.86868687 1.88888889 1.90909091 1.92929293 1.94949495\n",
      " 1.96969697 1.98989899 2.01010101 2.03030303 2.05050505 2.07070707\n",
      " 2.09090909 2.11111111 2.13131313 2.15151515 2.17171717 2.19191919\n",
      " 2.21212121 2.23232323 2.25252525 2.27272727 2.29292929 2.31313131\n",
      " 2.33333333 2.35353535 2.37373737 2.39393939 2.41414141 2.43434343\n",
      " 2.45454545 2.47474747 2.49494949 2.51515152 2.53535354 2.55555556\n",
      " 2.57575758 2.5959596  2.61616162 2.63636364 2.65656566 2.67676768\n",
      " 2.6969697  2.71717172 2.73737374 2.75757576 2.77777778 2.7979798\n",
      " 2.81818182 2.83838384 2.85858586 2.87878788 2.8989899  2.91919192\n",
      " 2.93939394 2.95959596 2.97979798 3.        ]\n",
      "Log Density: [-1.34338142 -1.3401791  -1.33725675 -1.33461001 -1.33223444 -1.33012546\n",
      " -1.32827839 -1.32668846 -1.32535077 -1.3242603  -1.32341195 -1.3228005\n",
      " -1.32242062 -1.3222669  -1.32233381 -1.32261574 -1.32310697 -1.32380172\n",
      " -1.3246941  -1.32577816 -1.32704787 -1.32849714 -1.33011982 -1.33190969\n",
      " -1.33386051 -1.33596599 -1.33821981 -1.34061564 -1.34314714 -1.34580795\n",
      " -1.34859175 -1.35149223 -1.3545031  -1.35761815 -1.36083119 -1.36413613\n",
      " -1.36752695 -1.37099773 -1.37454265 -1.37815604 -1.38183234 -1.38556616\n",
      " -1.38935227 -1.3931856  -1.39706131 -1.40097474 -1.40492145 -1.40889723\n",
      " -1.41289813 -1.41692044 -1.42096071 -1.42501578 -1.42908278 -1.43315911\n",
      " -1.43724251 -1.44133098 -1.4454229  -1.44951691 -1.45361202 -1.45770756\n",
      " -1.46180316 -1.46589883 -1.46999489 -1.47409198 -1.47819109 -1.48229354\n",
      " -1.48640094 -1.49051525 -1.49463873 -1.49877394 -1.50292374 -1.50709127\n",
      " -1.51127995 -1.51549349 -1.51973581 -1.5240111  -1.5283238  -1.53267853\n",
      " -1.53708015 -1.54153368 -1.54604437 -1.55061758 -1.55525885 -1.55997387\n",
      " -1.56476844 -1.56964846 -1.57461995 -1.579689   -1.58486179 -1.59014454\n",
      " -1.59554352 -1.60106504 -1.60671543 -1.61250104 -1.61842821 -1.62450327\n",
      " -1.63073255 -1.63712234 -1.64367888 -1.6504084 ]\n",
      "\n",
      "Class: yes, Feature: age_numeric\n",
      "Sample Points: [1.         1.02020202 1.04040404 1.06060606 1.08080808 1.1010101\n",
      " 1.12121212 1.14141414 1.16161616 1.18181818 1.2020202  1.22222222\n",
      " 1.24242424 1.26262626 1.28282828 1.3030303  1.32323232 1.34343434\n",
      " 1.36363636 1.38383838 1.4040404  1.42424242 1.44444444 1.46464646\n",
      " 1.48484848 1.50505051 1.52525253 1.54545455 1.56565657 1.58585859\n",
      " 1.60606061 1.62626263 1.64646465 1.66666667 1.68686869 1.70707071\n",
      " 1.72727273 1.74747475 1.76767677 1.78787879 1.80808081 1.82828283\n",
      " 1.84848485 1.86868687 1.88888889 1.90909091 1.92929293 1.94949495\n",
      " 1.96969697 1.98989899 2.01010101 2.03030303 2.05050505 2.07070707\n",
      " 2.09090909 2.11111111 2.13131313 2.15151515 2.17171717 2.19191919\n",
      " 2.21212121 2.23232323 2.25252525 2.27272727 2.29292929 2.31313131\n",
      " 2.33333333 2.35353535 2.37373737 2.39393939 2.41414141 2.43434343\n",
      " 2.45454545 2.47474747 2.49494949 2.51515152 2.53535354 2.55555556\n",
      " 2.57575758 2.5959596  2.61616162 2.63636364 2.65656566 2.67676768\n",
      " 2.6969697  2.71717172 2.73737374 2.75757576 2.77777778 2.7979798\n",
      " 2.81818182 2.83838384 2.85858586 2.87878788 2.8989899  2.91919192\n",
      " 2.93939394 2.95959596 2.97979798 3.        ]\n",
      "Log Density: [-1.54087606 -1.5274627  -1.51429792 -1.50138099 -1.48871121 -1.47628789\n",
      " -1.46411035 -1.45217794 -1.44049002 -1.42904598 -1.4178452  -1.40688712\n",
      " -1.39617117 -1.3856968  -1.37546349 -1.36547073 -1.35571803 -1.34620492\n",
      " -1.33693095 -1.3278957  -1.31909875 -1.31053971 -1.3022182  -1.29413387\n",
      " -1.28628639 -1.27867544 -1.27130073 -1.26416198 -1.25725894 -1.25059137\n",
      " -1.24415905 -1.23796179 -1.23199941 -1.22627176 -1.22077868 -1.21552008\n",
      " -1.21049584 -1.20570589 -1.20115018 -1.19682865 -1.1927413  -1.18888813\n",
      " -1.18526915 -1.1818844  -1.17873395 -1.17581787 -1.17313627 -1.17068926\n",
      " -1.16847699 -1.1664996  -1.16475729 -1.16325024 -1.16197869 -1.16094285\n",
      " -1.160143   -1.1595794  -1.15925236 -1.15916219 -1.15930923 -1.15969382\n",
      " -1.16031635 -1.16117721 -1.16227681 -1.16361559 -1.16519399 -1.16701248\n",
      " -1.16907156 -1.17137174 -1.17391354 -1.1766975  -1.17972419 -1.1829942\n",
      " -1.18650813 -1.19026659 -1.19427023 -1.19851969 -1.20301567 -1.20775883\n",
      " -1.21274991 -1.21798961 -1.22347869 -1.22921791 -1.23520804 -1.24144987\n",
      " -1.24794423 -1.25469192 -1.26169381 -1.26895074 -1.27646358 -1.28423323\n",
      " -1.29226059 -1.30054658 -1.30909212 -1.31789817 -1.32696568 -1.33629563\n",
      " -1.345889   -1.35574679 -1.36587001 -1.37625969]\n",
      "\n",
      "Class: no, Feature: income_numeric\n",
      "Sample Points: [1.         1.02020202 1.04040404 1.06060606 1.08080808 1.1010101\n",
      " 1.12121212 1.14141414 1.16161616 1.18181818 1.2020202  1.22222222\n",
      " 1.24242424 1.26262626 1.28282828 1.3030303  1.32323232 1.34343434\n",
      " 1.36363636 1.38383838 1.4040404  1.42424242 1.44444444 1.46464646\n",
      " 1.48484848 1.50505051 1.52525253 1.54545455 1.56565657 1.58585859\n",
      " 1.60606061 1.62626263 1.64646465 1.66666667 1.68686869 1.70707071\n",
      " 1.72727273 1.74747475 1.76767677 1.78787879 1.80808081 1.82828283\n",
      " 1.84848485 1.86868687 1.88888889 1.90909091 1.92929293 1.94949495\n",
      " 1.96969697 1.98989899 2.01010101 2.03030303 2.05050505 2.07070707\n",
      " 2.09090909 2.11111111 2.13131313 2.15151515 2.17171717 2.19191919\n",
      " 2.21212121 2.23232323 2.25252525 2.27272727 2.29292929 2.31313131\n",
      " 2.33333333 2.35353535 2.37373737 2.39393939 2.41414141 2.43434343\n",
      " 2.45454545 2.47474747 2.49494949 2.51515152 2.53535354 2.55555556\n",
      " 2.57575758 2.5959596  2.61616162 2.63636364 2.65656566 2.67676768\n",
      " 2.6969697  2.71717172 2.73737374 2.75757576 2.77777778 2.7979798\n",
      " 2.81818182 2.83838384 2.85858586 2.87878788 2.8989899  2.91919192\n",
      " 2.93939394 2.95959596 2.97979798 3.        ]\n",
      "Log Density: [-1.61861422 -1.60446149 -1.59054241 -1.57685614 -1.56340187 -1.55017878\n",
      " -1.53718612 -1.52442313 -1.51188909 -1.4995833  -1.48750509 -1.47565381\n",
      " -1.46402883 -1.45262957 -1.44145545 -1.43050593 -1.4197805  -1.40927866\n",
      " -1.39899997 -1.38894399 -1.37911031 -1.36949855 -1.36010839 -1.35093948\n",
      " -1.34199156 -1.33326434 -1.32475761 -1.31647117 -1.30840483 -1.30055846\n",
      " -1.29293194 -1.28552518 -1.27833815 -1.2713708  -1.26462314 -1.25809521\n",
      " -1.25178708 -1.24569882 -1.23983058 -1.23418249 -1.22875475 -1.22354756\n",
      " -1.21856116 -1.21379582 -1.20925185 -1.20492956 -1.20082931 -1.19695149\n",
      " -1.19329651 -1.18986482 -1.18665686 -1.18367316 -1.18091422 -1.17838059\n",
      " -1.17607286 -1.17399163 -1.17213753 -1.17051121 -1.16911335 -1.16794467\n",
      " -1.16700589 -1.16629776 -1.16582108 -1.16557664 -1.16556527 -1.16578782\n",
      " -1.16624517 -1.1669382  -1.16786784 -1.16903502 -1.17044071 -1.17208588\n",
      " -1.17397153 -1.17609868 -1.17846837 -1.18108165 -1.18393959 -1.18704329\n",
      " -1.19039386 -1.19399242 -1.19784011 -1.20193808 -1.20628751 -1.21088958\n",
      " -1.21574549 -1.22085644 -1.22622367 -1.23184841 -1.2377319  -1.24387541\n",
      " -1.2502802  -1.25694755 -1.26387876 -1.27107511 -1.27853791 -1.28626847\n",
      " -1.29426811 -1.30253817 -1.31107997 -1.31989484]\n",
      "\n",
      "Class: yes, Feature: income_numeric\n",
      "Sample Points: [1.         1.02020202 1.04040404 1.06060606 1.08080808 1.1010101\n",
      " 1.12121212 1.14141414 1.16161616 1.18181818 1.2020202  1.22222222\n",
      " 1.24242424 1.26262626 1.28282828 1.3030303  1.32323232 1.34343434\n",
      " 1.36363636 1.38383838 1.4040404  1.42424242 1.44444444 1.46464646\n",
      " 1.48484848 1.50505051 1.52525253 1.54545455 1.56565657 1.58585859\n",
      " 1.60606061 1.62626263 1.64646465 1.66666667 1.68686869 1.70707071\n",
      " 1.72727273 1.74747475 1.76767677 1.78787879 1.80808081 1.82828283\n",
      " 1.84848485 1.86868687 1.88888889 1.90909091 1.92929293 1.94949495\n",
      " 1.96969697 1.98989899 2.01010101 2.03030303 2.05050505 2.07070707\n",
      " 2.09090909 2.11111111 2.13131313 2.15151515 2.17171717 2.19191919\n",
      " 2.21212121 2.23232323 2.25252525 2.27272727 2.29292929 2.31313131\n",
      " 2.33333333 2.35353535 2.37373737 2.39393939 2.41414141 2.43434343\n",
      " 2.45454545 2.47474747 2.49494949 2.51515152 2.53535354 2.55555556\n",
      " 2.57575758 2.5959596  2.61616162 2.63636364 2.65656566 2.67676768\n",
      " 2.6969697  2.71717172 2.73737374 2.75757576 2.77777778 2.7979798\n",
      " 2.81818182 2.83838384 2.85858586 2.87878788 2.8989899  2.91919192\n",
      " 2.93939394 2.95959596 2.97979798 3.        ]\n",
      "Log Density: [-1.37625969 -1.36587001 -1.35574679 -1.345889   -1.33629563 -1.32696568\n",
      " -1.31789817 -1.30909212 -1.30054658 -1.29226059 -1.28423323 -1.27646358\n",
      " -1.26895074 -1.26169381 -1.25469192 -1.24794423 -1.24144987 -1.23520804\n",
      " -1.22921791 -1.22347869 -1.21798961 -1.21274991 -1.20775883 -1.20301567\n",
      " -1.19851969 -1.19427023 -1.19026659 -1.18650813 -1.1829942  -1.17972419\n",
      " -1.1766975  -1.17391354 -1.17137174 -1.16907156 -1.16701248 -1.16519399\n",
      " -1.16361559 -1.16227681 -1.16117721 -1.16031635 -1.15969382 -1.15930923\n",
      " -1.15916219 -1.15925236 -1.1595794  -1.160143   -1.16094285 -1.16197869\n",
      " -1.16325024 -1.16475729 -1.1664996  -1.16847699 -1.17068926 -1.17313627\n",
      " -1.17581787 -1.17873395 -1.1818844  -1.18526915 -1.18888813 -1.1927413\n",
      " -1.19682865 -1.20115018 -1.20570589 -1.21049584 -1.21552008 -1.22077868\n",
      " -1.22627176 -1.23199941 -1.23796179 -1.24415905 -1.25059137 -1.25725894\n",
      " -1.26416198 -1.27130073 -1.27867544 -1.28628639 -1.29413387 -1.3022182\n",
      " -1.31053971 -1.31909875 -1.3278957  -1.33693095 -1.34620492 -1.35571803\n",
      " -1.36547073 -1.37546349 -1.3856968  -1.39617117 -1.40688712 -1.4178452\n",
      " -1.42904598 -1.44049002 -1.45217794 -1.46411035 -1.47628789 -1.48871121\n",
      " -1.50138099 -1.51429792 -1.5274627  -1.54087606]\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'no'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Use kernel density estimation\u001b[39;00m\n\u001b[0;32m     19\u001b[0m kde \u001b[38;5;241m=\u001b[39m KernelDensity(bandwidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mkde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Generate some sample data points\u001b[39;00m\n\u001b[0;32m     23\u001b[0m sample_points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(df[feature]\u001b[38;5;241m.\u001b[39mmin(), df[feature]\u001b[38;5;241m.\u001b[39mmax(), \u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_kde.py:226\u001b[0m, in \u001b[0;36mKernelDensity.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbandwidth_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbandwidth\n\u001b[1;32m--> 226\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    230\u001b[0m         sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'no'"
     ]
    }
   ],
   "source": [
    "#A2\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import numpy as np\n",
    "\n",
    "age_mapping = {'<=30': 1, '31...40': 2, '>40': 3}\n",
    "df['age_numeric'] = df['age'].map(age_mapping)\n",
    "\n",
    "# Map income categories to numerical values\n",
    "income_mapping = {'low': 1, 'medium': 2, 'high': 3}\n",
    "df['income_numeric'] = df['income'].map(income_mapping)\n",
    "\n",
    "# Iterate through features and calculate class conditional densities\n",
    "for feature in ['age_numeric', 'income_numeric', 'student', 'credit_rating']:\n",
    "    for class_label in df['buys_computer'].unique():\n",
    "        # Extract data for the specific class\n",
    "        subset = df[df['buys_computer'] == class_label][feature].values.reshape(-1, 1)\n",
    "        \n",
    "        # Use kernel density estimation\n",
    "        kde = KernelDensity(bandwidth=1.0, kernel='gaussian')\n",
    "        kde.fit(subset)\n",
    "        \n",
    "        # Generate some sample data points\n",
    "        sample_points = np.linspace(df[feature].min(), df[feature].max(), 100).reshape(-1, 1)\n",
    "        \n",
    "        # Calculate the log density for the sample points\n",
    "        log_density = kde.score_samples(sample_points)\n",
    "        \n",
    "        # Display the results\n",
    "        print(f\"Class: {class_label}, Feature: {feature}\")\n",
    "        print(\"Sample Points:\", sample_points.flatten())\n",
    "        print(\"Log Density:\", log_density)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9619a985-dac7-4906-990d-7c14ae79fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared test for independence between student and buys_computer:\n",
      "Chi-squared statistic: 1.2444444444444445\n",
      "P-value: 0.2646162170835855\n",
      "****************************************\n",
      "Chi-squared test for independence between credit_rating and buys_computer:\n",
      "Chi-squared statistic: 0.16203703703703706\n",
      "P-value: 0.6872879493480017\n",
      "****************************************\n",
      "Chi-squared test for independence between buys_computer and buys_computer:\n",
      "Chi-squared statistic: 9.983209876543212\n",
      "P-value: 0.0015797405840629584\n",
      "****************************************\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['age_numeric', 'age_numeric']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17192\\2556098460.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mnumeric_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'age_numeric'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'income_numeric'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnumeric_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Drop rows with missing values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mvalid_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'age_numeric'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcorrelation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age_numeric'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6403\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6404\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6405\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6407\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6408\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['age_numeric', 'age_numeric']"
     ]
    }
   ],
   "source": [
    "#A3\n",
    "from scipy.stats import chi2_contingency, pearsonr\n",
    "\n",
    "categorical_features = ['student', 'credit_rating', 'buys_computer']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    contingency_table = pd.crosstab(df[feature], df['buys_computer'])\n",
    "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(f\"Chi-squared test for independence between {feature} and buys_computer:\")\n",
    "    print(f\"Chi-squared statistic: {chi2}\")\n",
    "    print(f\"P-value: {p}\")\n",
    "    print(f\"{'*' * 40}\")\n",
    "\n",
    "# Numeric features: Pearson correlation coefficient\n",
    "numeric_features = ['age_numeric', 'income_numeric']\n",
    "\n",
    "for feature in numeric_features:\n",
    "    # Drop rows with missing values\n",
    "    valid_data = df.dropna(subset=[feature, 'age_numeric'])\n",
    "    \n",
    "    correlation, p_value = pearsonr(valid_data[feature], valid_data['age_numeric'])\n",
    "    \n",
    "    print(f\"Pearson correlation coefficient between {feature} and age_numeric:\")\n",
    "    print(f\"Correlation coefficient: {correlation}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "    print(f\"{'*' * 40}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d88e90a-23bb-416d-9c1a-2a529adbb24d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Classifier Results:\n",
      "Accuracy: 0.33\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          no       0.00      0.00      0.00         1\n",
      "         yes       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.25      0.25      0.25         3\n",
      "weighted avg       0.33      0.33      0.33         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A4\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[['age', 'income', 'student', 'credit_rating']]\n",
    "y = df['buys_computer']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert categorical features to a dictionary format\n",
    "train_features = X_train.to_dict(orient='records')\n",
    "test_features = X_test.to_dict(orient='records')\n",
    "\n",
    "# Vectorize features using DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "X_train_vec = vectorizer.fit_transform(train_features)\n",
    "X_test_vec = vectorizer.transform(test_features)\n",
    "\n",
    "# Build a Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test_vec)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(\"Naïve Bayes Classifier Results:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "787e6a44-94c6-431c-baa2-06d845d05e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29654654654654655\n"
     ]
    }
   ],
   "source": [
    "#A5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load the data\n",
    "data =pd.read_csv(\"extracted_features_charrec.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "X = data.drop(columns=['class_name']) \n",
    "y = data['class_name']\n",
    "\n",
    "# Convert the data to NumPy arrays\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build and train the Naïve-Bayes classifier\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
